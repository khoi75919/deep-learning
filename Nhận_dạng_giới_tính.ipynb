{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nhận dạng giới tính.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMhX/1a6jo5iJ91PFOesxQo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khoi75919/deep-learning/blob/main/Nh%E1%BA%ADn_d%E1%BA%A1ng_gi%E1%BB%9Bi_t%C3%ADnh.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK-I_CnZG5jw",
        "outputId": "497a6442-9c29-4208-9b0a-f2b2072713ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXNa8jOWHJkd",
        "outputId": "1150ffbc-67ab-453e-b837-0ffc0980bd5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install scipy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhjwrQE9HSc1"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "try:\n",
        "  # Use the %tensorflow_version magic if in colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import dlib\n",
        "import cv2\n",
        "import time\n",
        "import math\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import bz2\n",
        "from random import randint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4gsUb0pHVBI",
        "outputId": "1ef07695-71f8-4e07-9fab-aaa2c71284d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "if not os.path.exists(os.path.abspath('.') + 'mmod_human_face_detector.dat.bz2'):\n",
        "    annotation_zip = tf.keras.utils.get_file('mmod_human_face_detector.dat.bz2',\n",
        "                            cache_subdir=os.path.abspath('.'),\n",
        "                            origin = \"http://dlib.net/files/mmod_human_face_detector.dat.bz2\")\n",
        "# Using pythons bz2 package to read the bz2 file in binary format and write it into a .dat file\n",
        "with bz2.open(\"mmod_human_face_detector.dat.bz2\", \"rb\") as f:\n",
        "    content = f.read()\n",
        "\n",
        "    with open(\"mmod_human_face_detector.dat\", \"wb\") as weights_file:\n",
        "        weights_file.write(content)\n",
        "\n",
        "os.remove(annotation_zip)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://dlib.net/files/mmod_human_face_detector.dat.bz2\n",
            "696320/694709 [==============================] - 1s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta3akP9sHXzh",
        "outputId": "c2a1101e-e8b9-4436-9dfb-33a7cfa6b4ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "dataset_url = 'https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki_crop.tar'\n",
        "annotation_folder = \"wiki_crop\"\n",
        "if not os.path.exists(os.path.abspath('.') + annotation_folder):\n",
        "    annotation_zip = tf.keras.utils.get_file('wiki.tar',\n",
        "                                            cache_subdir=os.path.abspath('.'),\n",
        "                                            origin = dataset_url,\n",
        "                                            extract = True)\n",
        "    os.remove(annotation_zip)\n",
        "data_key = 'wiki'\n",
        "mat_file = 'wiki.mat'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki_crop.tar\n",
            "811319296/811315200 [==============================] - 42s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQUUV9x1HwXL"
      },
      "source": [
        "mat = scipy.io.loadmat(annotation_folder+'/'+mat_file)\n",
        "data = mat[data_key]\n",
        "route = data[0][0][2][0]\n",
        "name = []\n",
        "age = []\n",
        "gender = []\n",
        "images = []\n",
        "total = 0\n",
        "project_path = \"drive/My Drive/Colab Notebooks/Tutorial/Gender Classifier\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx4i5ZLsH51g",
        "outputId": "da90103b-b35a-4d9c-c913-4cc5608a4b24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "cnn_face_detector = dlib.cnn_face_detection_model_v1(\"mmod_human_face_detector.dat\")\n",
        "plt.figure()\n",
        "i = 1\n",
        "\n",
        "while(i <= 4):\n",
        "    index = randint(0, len(route))\n",
        "    if((math.isnan(data[0][0][6][0][index]) == False and data[0][0][6][0][index] > 0)):\n",
        "        img = cv2.imread('wiki_crop/'+data[0][0][2][0][index][0])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        faces_cnn = cnn_face_detector(img, 1)\n",
        "\n",
        "        for face in faces_cnn:\n",
        "            offset_x , offset_y  = max(faces_cnn[0].rect.left(),0),max(faces_cnn[0].rect.top(),0)\n",
        "            target_width, target_height = faces_cnn[0].rect.right() - offset_x, faces_cnn[0].rect.bottom() - offset_y\n",
        "            target_width = min(target_width, img.shape[1]-offset_x)\n",
        "            target_height = min(target_height, img.shape[0]-offset_y)\n",
        "            # draw box over face\n",
        "            face_img = tf.image.crop_to_bounding_box(img, \n",
        "                                                    offset_y, offset_x, \n",
        "                                                    target_height,target_width)\n",
        "            cv2.rectangle(img, (offset_x,offset_y), (offset_x+target_width,offset_y+target_height), (0,255,0), 2)\n",
        "            face_img = tf.image.resize(face_img, (32, 32), method=tf.image.ResizeMethod.BICUBIC, antialias=True)\n",
        "            face_img = tf.dtypes.cast(face_img, tf.int32)\n",
        "            # Plotting images\n",
        "            plt.subplot(2, 2, i)\n",
        "            plt.imshow(img)\n",
        "            plt.title(data[0][0][4][0][index][0])\n",
        "            plt.subplot(2,2, i+1)\n",
        "            plt.imshow(face_img)\n",
        "            i += 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-52fcfc153ddd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcnn_face_detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detection_model_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mmod_human_face_detector.dat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error while calling cudaGetDevice(&the_device_id) in file /tmp/pip-wheel-66glv9rf/dlib/dlib/cuda/gpu_data.cpp:201. code: 100, reason: no CUDA-capable device is detected"
          ]
        }
      ]
    }
  ]
}